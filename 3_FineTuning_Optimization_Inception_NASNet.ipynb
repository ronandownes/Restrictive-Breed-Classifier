{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a72f58a-7676-447a-9d2b-d3beadc8913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 1: FINE-TUNING SETUP ---\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications, callbacks, optimizers, regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "FINE_TUNE_EPOCHS = 20\n",
    "PATIENCE = 5\n",
    "LEARNING_RATE_FT = 1e-5  # Lower LR for fine-tuning\n",
    "FIG_DIR = \"figures_finetune\"\n",
    "MODEL_DIR = \"models_finetune\"\n",
    "\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Load best pre-trained models\n",
    "nasnet_model = tf.keras.models.load_model(\"models/NASNetMobile_best.keras\")\n",
    "inception_model = tf.keras.models.load_model(\"models/InceptionV3_best.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f08e2e8-fd60-4c26-b709-ac53d5d56402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfroze last 20 layers of nasnet_mobile\n",
      "Trainable layers: 6/6\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 2: NASNETMOBILE FINE-TUNING (FIXED) ---\n",
    "\n",
    "def unfreeze_and_fine_tune_nasnet(model, unfreeze_layers=20):\n",
    "    \"\"\"Unfreeze last layers of NASNetMobile with NAS-specific regularization\"\"\"\n",
    "    \n",
    "    # Find the NASNetMobile base model layer\n",
    "    # It's typically the 4th layer in the functional API model\n",
    "    base_model = None\n",
    "    for layer in model.layers:\n",
    "        if 'nasnet' in layer.name.lower():\n",
    "            base_model = layer\n",
    "            break\n",
    "    \n",
    "    if base_model is None:\n",
    "        print(\"NASNetMobile base model not found. Using layer 4 as fallback.\")\n",
    "        base_model = model.layers[4]\n",
    "    \n",
    "    # Unfreeze the base model\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Freeze all but the last N layers of the base model\n",
    "    for layer in base_model.layers[:-unfreeze_layers]:\n",
    "        layer.trainable = False\n",
    "        # Add regularization to unfrozen layers\n",
    "    for layer in base_model.layers[-unfreeze_layers:]:\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            layer.kernel_regularizer = regularizers.l2(0.0001)\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(\n",
    "            learning_rate=LEARNING_RATE_FT,\n",
    "            clipnorm=1.0\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall', 'auc']\n",
    "    )\n",
    "    \n",
    "    print(f\"Unfroze last {unfreeze_layers} layers of {base_model.name}\")\n",
    "    print(f\"Trainable layers: {sum([l.trainable for l in model.layers])}/{len(model.layers)}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Apply fine-tuning to NASNetMobile\n",
    "nasnet_ft = unfreeze_and_fine_tune_nasnet(nasnet_model)\n",
    "\n",
    "# NASNetMobile-specific callbacks\n",
    "nasnet_callbacks = [\n",
    "    callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True, min_delta=0.0001),\n",
    "    callbacks.ReduceLROnPlateau(factor=0.2, patience=3, min_lr=1e-7),\n",
    "    callbacks.ModelCheckpoint(f\"{MODEL_DIR}/nasnet_ft_best.keras\", save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ca4ec4-f1e1-425d-a2b1-5575241af507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfroze last 15 layers of inception_v3\n",
      "Trainable layers: 6/6\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 3: INCEPTIONV3 FINE-TUNING (FIXED) ---\n",
    "\n",
    "def unfreeze_and_fine_tune_inception(model, unfreeze_layers=15):\n",
    "    \"\"\"Unfreeze InceptionV3 with precision-focused regularization\"\"\"\n",
    "    \n",
    "    # Find the InceptionV3 base model layer\n",
    "    base_model = None\n",
    "    for layer in model.layers:\n",
    "        if 'inception' in layer.name.lower() and 'v3' in layer.name.lower():\n",
    "            base_model = layer\n",
    "            break\n",
    "    \n",
    "    if base_model is None:\n",
    "        print(\"InceptionV3 base model not found. Using layer 4 as fallback.\")\n",
    "        base_model = model.layers[4]\n",
    "    \n",
    "    # Unfreeze the base model\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Freeze all but the last N layers\n",
    "    for layer in base_model.layers[:-unfreeze_layers]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Add regularization to unfrozen layers\n",
    "    for layer in base_model.layers[-unfreeze_layers:]:\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            layer.kernel_regularizer = regularizers.l2(0.0005)\n",
    "    \n",
    "    # Recompile with precision focus\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(\n",
    "            learning_rate=LEARNING_RATE_FT/2,\n",
    "            clipvalue=0.5\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall', 'auc']\n",
    "    )\n",
    "    \n",
    "    print(f\"Unfroze last {unfreeze_layers} layers of {base_model.name}\")\n",
    "    print(f\"Trainable layers: {sum([l.trainable for l in model.layers])}/{len(model.layers)}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Apply fine-tuning to InceptionV3\n",
    "inception_ft = unfreeze_and_fine_tune_inception(inception_model)\n",
    "\n",
    "# Precision-focused callbacks\n",
    "inception_callbacks = [\n",
    "    callbacks.EarlyStopping(monitor='val_precision', patience=PATIENCE, mode='max', restore_best_weights=True),\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_precision', factor=0.3, patience=2, mode='max'),\n",
    "    callbacks.ModelCheckpoint(f\"{MODEL_DIR}/inception_ft_best.keras\", monitor='val_precision', save_best_only=True, mode='max')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29f81b1-9b68-4977-b8c9-8d96d59f5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1120 files belonging to 2 classes.\n",
      "Found 229 files belonging to 2 classes.\n",
      "Found 237 files belonging to 2 classes.\n",
      "Datasets loaded successfully!\n",
      "Train batches: 35, Val batches: 8, Test batches: 8\n"
     ]
    }
   ],
   "source": [
    "# --- LOAD DATASETS ---\n",
    "def prepare_dataset(dir_path, shuffle=True):\n",
    "    ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dir_path,\n",
    "        labels=\"inferred\", \n",
    "        label_mode=\"binary\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=IMG_SIZE,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    ds = ds.map(lambda x, y: (tf.cast(x, tf.float32), y))  # No /255.0 - preprocessing handled by model\n",
    "    return ds\n",
    "\n",
    "# Load the datasets\n",
    "train_ds = prepare_dataset(\"train\", shuffle=True)\n",
    "val_ds = prepare_dataset(\"val\", shuffle=False) \n",
    "test_ds = prepare_dataset(\"test\", shuffle=False)\n",
    "\n",
    "# Optimize the pipeline\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"Datasets loaded successfully!\")\n",
    "print(f\"Train batches: {len(train_ds)}, Val batches: {len(val_ds)}, Test batches: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ebd60f-8b74-4696-84d0-abe7028a97fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting InceptionV3 fine-tuning...\n",
      "Epoch 1/20\n",
      "35/35 - 44s - 1s/step - accuracy: 0.9018 - auc: 0.9853 - loss: 0.2462 - precision: 0.8486 - recall: 0.9843 - val_accuracy: 0.9563 - val_auc: 0.9918 - val_loss: 0.1307 - val_precision: 0.9817 - val_recall: 0.9304 - learning_rate: 5.0000e-06\n",
      "Epoch 2/20\n",
      "35/35 - 29s - 834ms/step - accuracy: 0.9366 - auc: 0.9904 - loss: 0.1761 - precision: 0.9026 - recall: 0.9826 - val_accuracy: 0.9563 - val_auc: 0.9917 - val_loss: 0.1333 - val_precision: 0.9817 - val_recall: 0.9304 - learning_rate: 5.0000e-06\n",
      "Epoch 3/20\n",
      "35/35 - 31s - 888ms/step - accuracy: 0.9429 - auc: 0.9892 - loss: 0.1650 - precision: 0.9223 - recall: 0.9704 - val_accuracy: 0.9563 - val_auc: 0.9922 - val_loss: 0.1359 - val_precision: 0.9817 - val_recall: 0.9304 - learning_rate: 5.0000e-06\n",
      "Epoch 4/20\n",
      "35/35 - 29s - 826ms/step - accuracy: 0.9411 - auc: 0.9863 - loss: 0.1702 - precision: 0.9380 - recall: 0.9478 - val_accuracy: 0.9563 - val_auc: 0.9919 - val_loss: 0.1358 - val_precision: 0.9817 - val_recall: 0.9304 - learning_rate: 1.5000e-06\n",
      "Epoch 5/20\n",
      "35/35 - 29s - 830ms/step - accuracy: 0.9589 - auc: 0.9882 - loss: 0.1534 - precision: 0.9616 - recall: 0.9583 - val_accuracy: 0.9520 - val_auc: 0.9918 - val_loss: 0.1361 - val_precision: 0.9727 - val_recall: 0.9304 - learning_rate: 1.5000e-06\n",
      "Epoch 6/20\n",
      "35/35 - 30s - 867ms/step - accuracy: 0.9384 - auc: 0.9857 - loss: 0.1696 - precision: 0.9317 - recall: 0.9496 - val_accuracy: 0.9520 - val_auc: 0.9919 - val_loss: 0.1366 - val_precision: 0.9643 - val_recall: 0.9391 - learning_rate: 4.5000e-07\n",
      "\n",
      "Evaluating fine-tuned InceptionV3...\n",
      "Fine-tuned Test Accuracy: 0.9620\n",
      "Fine-tuned Test Precision: 0.9907\n",
      "Fine-tuned Test AUC: 0.9815\n",
      "Fine-tuned model saved!\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 4: RUN FINE-TUNING FOR INCEPTIONV3 ---\n",
    "print(\"Starting InceptionV3 fine-tuning...\")\n",
    "\n",
    "history = inception_ft.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    callbacks=inception_callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "print(\"\\nEvaluating fine-tuned InceptionV3...\")\n",
    "test_results = inception_ft.evaluate(test_ds, verbose=0)\n",
    "print(f\"Fine-tuned Test Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Fine-tuned Test Precision: {test_results[2]:.4f}\")\n",
    "print(f\"Fine-tuned Test AUC: {test_results[4]:.4f}\")\n",
    "\n",
    "# Save final model\n",
    "inception_ft.save(f\"{MODEL_DIR}/inceptionv3_final.keras\")\n",
    "print(\"Fine-tuned model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff30faad-7617-4884-8bdb-0c206dfa8e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NASNetMobile fine-tuning...\n",
      "Epoch 1/20\n",
      "35/35 - 58s - 2s/step - accuracy: 0.9536 - auc: 0.9875 - loss: 0.1346 - precision: 0.9548 - recall: 0.9548 - val_accuracy: 0.9432 - val_auc: 0.9939 - val_loss: 0.1159 - val_precision: 0.9722 - val_recall: 0.9130 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "35/35 - 27s - 775ms/step - accuracy: 0.9473 - auc: 0.9880 - loss: 0.1363 - precision: 0.9510 - recall: 0.9461 - val_accuracy: 0.9432 - val_auc: 0.9941 - val_loss: 0.1168 - val_precision: 0.9722 - val_recall: 0.9130 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "35/35 - 28s - 808ms/step - accuracy: 0.9545 - auc: 0.9914 - loss: 0.1195 - precision: 0.9613 - recall: 0.9496 - val_accuracy: 0.9432 - val_auc: 0.9941 - val_loss: 0.1171 - val_precision: 0.9722 - val_recall: 0.9130 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "35/35 - 27s - 783ms/step - accuracy: 0.9545 - auc: 0.9884 - loss: 0.1286 - precision: 0.9645 - recall: 0.9461 - val_accuracy: 0.9476 - val_auc: 0.9941 - val_loss: 0.1178 - val_precision: 0.9813 - val_recall: 0.9130 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "35/35 - 28s - 797ms/step - accuracy: 0.9491 - auc: 0.9891 - loss: 0.1318 - precision: 0.9576 - recall: 0.9426 - val_accuracy: 0.9476 - val_auc: 0.9941 - val_loss: 0.1179 - val_precision: 0.9813 - val_recall: 0.9130 - learning_rate: 2.0000e-06\n",
      "Epoch 6/20\n",
      "35/35 - 27s - 784ms/step - accuracy: 0.9518 - auc: 0.9887 - loss: 0.1316 - precision: 0.9611 - recall: 0.9443 - val_accuracy: 0.9476 - val_auc: 0.9941 - val_loss: 0.1178 - val_precision: 0.9813 - val_recall: 0.9130 - learning_rate: 2.0000e-06\n",
      "\n",
      "Evaluating fine-tuned NASNetMobile...\n",
      "Fine-tuned Test Accuracy: 0.9705\n",
      "Fine-tuned Test Precision: 0.9909\n",
      "Fine-tuned Test AUC: 0.9875\n",
      "Fine-tuned NASNetMobile saved!\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 4: RUN NASNETMOBILE FINE-TUNING ---\n",
    "print(\"Starting NASNetMobile fine-tuning...\")\n",
    "\n",
    "history_nasnet = nasnet_ft.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    callbacks=nasnet_callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "print(\"\\nEvaluating fine-tuned NASNetMobile...\")\n",
    "test_results_nasnet = nasnet_ft.evaluate(test_ds, verbose=0)\n",
    "print(f\"Fine-tuned Test Accuracy: {test_results_nasnet[1]:.4f}\")\n",
    "print(f\"Fine-tuned Test Precision: {test_results_nasnet[2]:.4f}\") \n",
    "print(f\"Fine-tuned Test AUC: {test_results_nasnet[4]:.4f}\")\n",
    "\n",
    "# Save final model\n",
    "nasnet_ft.save(f\"{MODEL_DIR}/nasnet_final.keras\")\n",
    "print(\"Fine-tuned NASNetMobile saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a06b71-cb25-4521-99b1-520b79b756ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ensemble predictions...\n",
      "\n",
      "🎯 ENSEMBLE PERFORMANCE (NASNetMobile 60% + InceptionV3 40%):\n",
      "Accuracy:   0.9747\n",
      "Precision:  1.0000\n",
      "Recall:     0.9478\n",
      "AUC:        0.9872\n",
      "\n",
      "📊 COMPARISON:\n",
      "               Accuracy  Precision  AUC\n",
      "NASNetMobile:   0.9705    0.9909     0.9875\n",
      "InceptionV3:    0.9620    0.9907     0.9815\n",
      "Ensemble:       0.9747    1.0000     0.9872\n",
      "\n",
      "📈 CONFUSION MATRIX:\n",
      "[[122   0]\n",
      " [  6 109]]\n",
      "\n",
      "📝 CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98       122\n",
      "         1.0       1.00      0.95      0.97       115\n",
      "\n",
      "    accuracy                           0.97       237\n",
      "   macro avg       0.98      0.97      0.97       237\n",
      "weighted avg       0.98      0.97      0.97       237\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true, ensemble_pred))\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Save ensemble predictions for analysis\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m ensemble_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_label\u001b[39m\u001b[38;5;124m'\u001b[39m: y_true,\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnasnet_probs\u001b[39m\u001b[38;5;124m'\u001b[39m: nasnet_ft\u001b[38;5;241m.\u001b[39mpredict(test_ds, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minception_probs\u001b[39m\u001b[38;5;124m'\u001b[39m: inception_ft\u001b[38;5;241m.\u001b[39mpredict(test_ds, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble_probs\u001b[39m\u001b[38;5;124m'\u001b[39m: ensemble_probs\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble_pred\u001b[39m\u001b[38;5;124m'\u001b[39m: ensemble_pred\n\u001b[0;32m     58\u001b[0m })\n\u001b[0;32m     59\u001b[0m ensemble_results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOG_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/ensemble_predictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m💾 Ensemble predictions saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOG_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/ensemble_predictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# --- CELL 5: CREATE ENSEMBLE ---\n",
    "def create_weighted_ensemble(model1, model2, test_ds, weight1=0.6, weight2=0.4):\n",
    "    \"\"\"Create weighted ensemble of two models\"\"\"\n",
    "    print(\"Generating ensemble predictions...\")\n",
    "    \n",
    "    # Get predictions from both models\n",
    "    preds1 = model1.predict(test_ds, verbose=0)\n",
    "    preds2 = model2.predict(test_ds, verbose=0)\n",
    "    \n",
    "    # Weighted average (NASNetMobile gets higher weight since it performed better)\n",
    "    ensemble_pred_probs = (preds1 * weight1) + (preds2 * weight2)\n",
    "    ensemble_pred = (ensemble_pred_probs > 0.5).astype(int).flatten()\n",
    "    \n",
    "    return ensemble_pred, ensemble_pred_probs\n",
    "\n",
    "# Create ensemble (60% NASNetMobile, 40% InceptionV3)\n",
    "ensemble_pred, ensemble_probs = create_weighted_ensemble(nasnet_ft, inception_ft, test_ds, weight1=0.6, weight2=0.4)\n",
    "\n",
    "# Get true labels\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "# Evaluate ensemble performance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "ensemble_acc = accuracy_score(y_true, ensemble_pred)\n",
    "ensemble_precision = precision_score(y_true, ensemble_pred)\n",
    "ensemble_recall = recall_score(y_true, ensemble_pred)\n",
    "ensemble_auc = roc_auc_score(y_true, ensemble_probs)\n",
    "\n",
    "print(f\"\\n🎯 ENSEMBLE PERFORMANCE (NASNetMobile 60% + InceptionV3 40%):\")\n",
    "print(f\"Accuracy:   {ensemble_acc:.4f}\")\n",
    "print(f\"Precision:  {ensemble_precision:.4f}\")\n",
    "print(f\"Recall:     {ensemble_recall:.4f}\")\n",
    "print(f\"AUC:        {ensemble_auc:.4f}\")\n",
    "\n",
    "# Compare with individual models\n",
    "print(f\"\\n📊 COMPARISON:\")\n",
    "print(f\"               Accuracy  Precision  AUC\")\n",
    "print(f\"NASNetMobile:   {test_results_nasnet[1]:.4f}    {test_results_nasnet[2]:.4f}     {test_results_nasnet[4]:.4f}\")\n",
    "print(f\"InceptionV3:    {test_results[1]:.4f}    {test_results[2]:.4f}     {test_results[4]:.4f}\")\n",
    "print(f\"Ensemble:       {ensemble_acc:.4f}    {ensemble_precision:.4f}     {ensemble_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\n📈 CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_true, ensemble_pred))\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\n📝 CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_true, ensemble_pred))\n",
    "\n",
    "# Save ensemble predictions for analysis\n",
    "ensemble_results = pd.DataFrame({\n",
    "    'true_label': y_true,\n",
    "    'nasnet_probs': nasnet_ft.predict(test_ds, verbose=0).flatten(),\n",
    "    'inception_probs': inception_ft.predict(test_ds, verbose=0).flatten(),\n",
    "    'ensemble_probs': ensemble_probs.flatten(),\n",
    "    'ensemble_pred': ensemble_pred\n",
    "})\n",
    "ensemble_results.to_csv(f\"{LOG_DIR}/ensemble_predictions.csv\", index=False)\n",
    "print(f\"\\n💾 Ensemble predictions saved to: {LOG_DIR}/ensemble_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e2744-bd16-4933-9243-5eae81fd93fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973f849-73fa-496e-9e4b-c08a65e4e220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e79c86-2b5f-480e-acb7-4aba846a9db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73511399-58c3-49e1-9acc-881142bcbdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07bdd7-0280-4877-a93b-54a5baa33f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
